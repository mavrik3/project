{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Input\n",
    "import os\n",
    "import logging\n",
    "import IQ as IQ\n",
    "\n",
    "logging.basicConfig(filename='adversarial_results.log',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "iq = IQ.IQ(Fc=2439810000 + 0.1e4)\n",
    "\n",
    "def RV_CNN(X_train, y_train, X_test, y_test):\n",
    "    input_data = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(filters=16, kernel_size=5, activation='relu')(input_data)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.L2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(y_test.shape[1], activation='softmax')(x)\n",
    "    model = Model(inputs=input_data, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return model, accuracy\n",
    "\n",
    "def add_gaussian_noise(X, snr_db):\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    power_signal = np.mean(np.abs(X) ** 2, axis=1, keepdims=True)\n",
    "    power_noise = power_signal / snr_linear\n",
    "    noise = np.sqrt(power_noise / 2) * np.random.randn(*X.shape)\n",
    "    return X + noise\n",
    "\n",
    "def add_multipath(X, num_paths=3):\n",
    "    w = np.random.rand(num_paths)\n",
    "    w /= w.sum()\n",
    "    mp_signals = [np.roll(X, shift=i, axis=1)*wt for i, wt in enumerate(w)]\n",
    "    return np.sum(mp_signals, axis=0)\n",
    "\n",
    "def add_rayleigh_fading(X):\n",
    "    f = np.sqrt(np.random.exponential(scale=1, size=X.shape))\n",
    "    return X * f\n",
    "\n",
    "def fgsm_attack(model, X, y, epsilon=0.01, targeted=False, target_class=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(X)\n",
    "        predictions = model(X)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(\n",
    "            to_categorical(target_class, y.shape[1]) if targeted else y, predictions\n",
    "        )\n",
    "    gradient = tape.gradient(loss, X)\n",
    "    pert = epsilon * tf.sign(gradient)\n",
    "    return X - pert if targeted else X + pert\n",
    "\n",
    "def pgd_attack(model, X, y, epsilon=0.01, alpha=0.001, num_steps=40, targeted=False, target_class=None):\n",
    "    X_adv = X\n",
    "    for _ in range(num_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(X_adv)\n",
    "            predictions = model(X_adv)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(\n",
    "                to_categorical(target_class, y.shape[1]) if targeted else y, predictions\n",
    "            )\n",
    "        grad = tape.gradient(loss, X_adv)\n",
    "        pert = alpha * tf.sign(grad)\n",
    "        X_adv = X_adv - pert if targeted else X_adv + pert\n",
    "        X_adv = tf.clip_by_value(X_adv, X - epsilon, X + epsilon)\n",
    "    return X_adv\n",
    "\n",
    "def cw_attack(model, X, y, confidence=0.0, targeted=False, target_class=None, max_iterations=1000, learning_rate=0.01):\n",
    "    def loss_fn(logits, labels):\n",
    "        real = tf.reduce_sum(labels*logits, axis=1)\n",
    "        other = tf.reduce_max((1 - labels)*logits - labels*1e4, axis=1)\n",
    "        return tf.maximum(0.0, other - real + confidence) if targeted else tf.maximum(0.0, real - other + confidence)\n",
    "\n",
    "    perturbation = tf.Variable(tf.zeros_like(X))\n",
    "    opt = tf.optimizers.Adam(learning_rate)\n",
    "    tgt_y = to_categorical(target_class, y.shape[1]) if targeted else y\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            adv_x = tf.clip_by_value(X + perturbation, 0, 1)\n",
    "            logits = model(adv_x)\n",
    "            loss = tf.reduce_mean(loss_fn(logits, tgt_y))\n",
    "        grad = tape.gradient(loss, perturbation)\n",
    "        opt.apply_gradients([(grad, perturbation)])\n",
    "    return tf.clip_by_value(X + perturbation, 0, 1)\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "def process_dataframe(df):\n",
    "    if 'I' in df.columns and 'Q' in df.columns:\n",
    "        if df['I'].apply(lambda x: isinstance(x, (list, np.ndarray))).all() and df['Q'].apply(lambda x: isinstance(x, (list, np.ndarray))).all():\n",
    "            df['I'] = df['I'].apply(lambda x: np.array(x, dtype=np.float64))\n",
    "            df['Q'] = df['Q'].apply(lambda x: np.array(x, dtype=np.float64))\n",
    "            df['frame'] = df.apply(lambda row: row['I'] + row['Q'] * 1j, axis=1)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    else:\n",
    "        raise KeyError()\n",
    "    return df\n",
    "\n",
    "def configCreator(downSampleRate=1, cutoff=1e6):\n",
    "    return {\n",
    "        iq.butter: {'Fs': iq.Fs // downSampleRate, \"cutoff\": cutoff},\n",
    "        iq.downSample: {'downSampleRate': downSampleRate, \"shift\": 0},\n",
    "        iq.demodulate: {'Fs': iq.Fs}\n",
    "    }\n",
    "\n",
    "def freqCreator():\n",
    "    return {\n",
    "        iq.gradient: {},\n",
    "        iq.unwrapPhase: {},\n",
    "        iq.phase: {},\n",
    "    }\n",
    "\n",
    "def runForExperiment(df, target, mode, query, configurations):\n",
    "    if df[target].dtype == object:\n",
    "        df[target] = df[target].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "    if df[target].dtype == object:\n",
    "        df[target] = df[target].astype(str).astype(int)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[target] = label_encoder.fit_transform(df[target])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    best_config = None\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_X_test = None\n",
    "    best_y_test = None\n",
    "\n",
    "    for config_name, config_methods in configurations.items():\n",
    "        try:\n",
    "            if mode == 'freq':\n",
    "                temp = iq.apply(methods={**freqCreator(), **config_methods}, frame=df['frame'])\n",
    "            else:\n",
    "                temp = iq.apply(methods=config_methods, frame=df['frame'])\n",
    "\n",
    "            if mode == 'IQSplit':\n",
    "                temp = temp.apply(lambda x: np.concatenate([np.real(x), np.imag(x)]))\n",
    "            else:\n",
    "                temp = temp.apply(lambda x: x[:min(2000, len(x))])\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(temp, df[target], test_size=0.2, random_state=42)\n",
    "            y_train_enc = to_categorical(y_train, num_classes=num_classes)\n",
    "            y_test_enc = to_categorical(y_test, num_classes=num_classes)\n",
    "            X_train = tf.convert_to_tensor(X_train.tolist(), dtype=tf.float32)\n",
    "            X_test = tf.convert_to_tensor(X_test.tolist(), dtype=tf.float32)\n",
    "            model, acc = RV_CNN(X_train, y_train_enc, X_test, y_test_enc)\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_config = config_name\n",
    "                best_model = model\n",
    "                best_X_test = X_test\n",
    "                best_y_test = y_test_enc\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if best_model is not None:\n",
    "        for snr in [10, 20, 30]:\n",
    "            X_g = add_gaussian_noise(best_X_test.numpy(), snr)\n",
    "            X_m = add_multipath(best_X_test.numpy())\n",
    "            X_f = add_rayleigh_fading(best_X_test.numpy())\n",
    "            y_true = np.argmax(best_y_test, axis=1)\n",
    "\n",
    "            for pertX in [X_g, X_m, X_f]:\n",
    "                y_pred = np.argmax(best_model.predict(pertX), axis=1)\n",
    "                evaluate_performance(y_true, y_pred)\n",
    "\n",
    "        # Non-targeted\n",
    "        attack_configurations = [\n",
    "            {'type': 'fgsm', 'params': {'epsilon': 0.01, 'targeted': False}},\n",
    "            {'type': 'pgd', 'params': {'epsilon': 0.01, 'alpha': 0.001, 'num_steps': 40, 'targeted': False}},\n",
    "            {'type': 'cw', 'params': {'confidence': 0.0, 'targeted': False, 'max_iterations': 1000, 'learning_rate': 0.01}},\n",
    "        ]\n",
    "\n",
    "        # Targeted: choose a target class (e.g., 0)\n",
    "        targeted_attack_configurations = [\n",
    "            {'type': 'fgsm', 'params': {'epsilon': 0.01, 'targeted': True, 'target_class': 0}},\n",
    "            {'type': 'pgd', 'params': {'epsilon': 0.01, 'alpha': 0.001, 'num_steps': 40, 'targeted': True, 'target_class': 0}},\n",
    "            {'type': 'cw', 'params': {'confidence': 0.0, 'targeted': True, 'max_iterations': 1000, 'learning_rate': 0.01, 'target_class': 0}},\n",
    "        ]\n",
    "\n",
    "        for attack in attack_configurations + targeted_attack_configurations:\n",
    "            try:\n",
    "                if attack['type'] == 'fgsm':\n",
    "                    X_adv = fgsm_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "                elif attack['type'] == 'pgd':\n",
    "                    X_adv = pgd_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "                elif attack['type'] == 'cw':\n",
    "                    X_adv = cw_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "\n",
    "                y_pred_adv = np.argmax(best_model.predict(X_adv), axis=1)\n",
    "                y_true = np.argmax(best_y_test, axis=1)\n",
    "                metrics = evaluate_performance(y_true, y_pred_adv)\n",
    "                logging.info(f\"Attack: {attack['type']}, Targeted: {attack['params'].get('targeted', False)}, Metrics: {metrics}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "queries = {\n",
    "    'E1': {'pkl_file': 'data/E1.pkl', 'target': 'dvc'},\n",
    "    'E2': {'pkl_file': 'data/E2.pkl', 'target': 'pos'},\n",
    "    'E3': {'pkl_file': 'data/E3.pkl', 'target': 'pos'},\n",
    "    'E4': {'pkl_file': 'data/E4.pkl', 'target': 'dvc'},\n",
    "    'E5': {'pkl_file': 'data/E5.pkl', 'target': 'pos'},\n",
    "    'E6': {'pkl_file': 'data/E6.pkl', 'target': 'dvc'},\n",
    "    'E7': {'pkl_file': 'data/E7.pkl', 'target': 'dvc'},\n",
    "    'E8': {'pkl_file': 'data/E8.pkl', 'target': 'dvc'},\n",
    "    'E9': {'pkl_file': 'data/E9.pkl', 'target': 'dvc'},\n",
    "    'E10': {'pkl_file': 'data/E10.pkl', 'target': 'dvc'},\n",
    "    'E11': {'pkl_file': 'data/E11.pkl', 'target': 'dvc'},\n",
    "}\n",
    "\n",
    "configurations = {\n",
    "    'butter4MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=4e6),\n",
    "    'butter4MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=4e6),\n",
    "    'butter2MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=2e6),\n",
    "    'butter2MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=2e6),\n",
    "    'butter2MHz_Fs5MHz': configCreator(downSampleRate=20, cutoff=2e6),\n",
    "    'butter1MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=1e6),\n",
    "    'butter1MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=1e6),\n",
    "    'butter1MHz_Fs5MHz': configCreator(downSampleRate=20, cutoff=1e6),\n",
    "    'butter1MHz_Fs2.5MHz': configCreator(downSampleRate=40, cutoff=1e6),\n",
    "}\n",
    "\n",
    "Experiments = ['freq', 'IQSplit', 'RV_CNN']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for q, info in queries.items():\n",
    "        try:\n",
    "            with open(info['pkl_file'], 'rb') as f:\n",
    "                df = pickle.load(f)\n",
    "            df = process_dataframe(df)\n",
    "            for experiment in Experiments:\n",
    "                runForExperiment(df, info['target'], experiment, info, configurations)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Input\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='adversarial_results.log',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# Create cache directory\n",
    "cache_dir = 'data'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# IQ Module\n",
    "import IQ as IQ\n",
    "\n",
    "# Initialize IQ\n",
    "iq = IQ.IQ(Fc=2439810000 + 0.1e4)\n",
    "\n",
    "def RV_CNN(X_train, y_train, X_test, y_test):\n",
    "    input_data = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(filters=16, kernel_size=5, activation='relu')(input_data)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.L2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(y_test.shape[1], activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    return model, accuracy\n",
    "\n",
    "def add_noise(X, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "def fgsm_attack(model, X, y, epsilon=0.01, targeted=False, target_class=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(X)\n",
    "        predictions = model(X)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y, predictions) if not targeted \\\n",
    "               else tf.keras.losses.categorical_crossentropy(to_categorical(target_class, num_classes=y.shape[1]), predictions)\n",
    "    gradient = tape.gradient(loss, X)\n",
    "    perturbation = epsilon * tf.sign(gradient)\n",
    "    return X + perturbation if not targeted else X - perturbation\n",
    "\n",
    "def pgd_attack(model, X, y, epsilon=0.01, alpha=0.001, num_steps=40, targeted=False, target_class=None):\n",
    "    X_adv = X\n",
    "    for _ in range(num_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(X_adv)\n",
    "            predictions = model(X_adv)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions) if not targeted \\\n",
    "                   else tf.keras.losses.categorical_crossentropy(to_categorical(target_class, num_classes=y.shape[1]), predictions)\n",
    "        gradient = tape.gradient(loss, X_adv)\n",
    "        perturbation = alpha * tf.sign(gradient)\n",
    "        X_adv = tf.clip_by_value(X_adv + perturbation if not targeted else X_adv - perturbation, X - epsilon, X + epsilon)\n",
    "    return X_adv\n",
    "\n",
    "def cw_attack(model, X, y, confidence=0.0, targeted=False, target_class=None, max_iterations=1000, learning_rate=0.01):\n",
    "    def loss_fn(logits, labels):\n",
    "        real = tf.reduce_sum(labels * logits, axis=1)\n",
    "        other = tf.reduce_max((1 - labels) * logits - labels * 1e4, axis=1)\n",
    "        if targeted:\n",
    "            return tf.maximum(0.0, other - real + confidence)\n",
    "        else:\n",
    "            return tf.maximum(0.0, real - other + confidence)\n",
    "\n",
    "    perturbation = tf.Variable(tf.zeros_like(X))\n",
    "    optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            adv_x = tf.clip_by_value(X + perturbation, 0, 1)\n",
    "            logits = model(adv_x)\n",
    "            loss = tf.reduce_mean(loss_fn(logits, y))\n",
    "        gradients = tape.gradient(loss, perturbation)\n",
    "        optimizer.apply_gradients([(gradients, perturbation)])\n",
    "\n",
    "    return tf.clip_by_value(X + perturbation, 0, 1)\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "def process_dataframe(df):\n",
    "    if 'I' in df.columns and 'Q' in df.columns:\n",
    "        if df['I'].apply(lambda x: isinstance(x, (list, np.ndarray))).all() and \\\n",
    "           df['Q'].apply(lambda x: isinstance(x, (list, np.ndarray))).all():\n",
    "            df['I'] = df['I'].apply(lambda x: np.array(x, dtype=np.float64))\n",
    "            df['Q'] = df['Q'].apply(lambda x: np.array(x, dtype=np.float64))\n",
    "            df['frame'] = df.apply(lambda row: row['I'] + row['Q'] * 1j, axis=1)\n",
    "            print(\"'frame' column added successfully.\")\n",
    "        else:\n",
    "            raise ValueError(\"'I' and 'Q' columns must contain lists or arrays.\")\n",
    "    else:\n",
    "        raise KeyError(\"'I' and 'Q' columns are missing in the DataFrame.\")\n",
    "    return df\n",
    "\n",
    "def configCreator(downSampleRate=1, cutoff=1e6):\n",
    "    return {\n",
    "        iq.butter: {'Fs': iq.Fs // downSampleRate, \"cutoff\": cutoff},\n",
    "        iq.downSample: {'downSampleRate': downSampleRate, \"shift\": 0},\n",
    "        iq.demodulate: {'Fs': iq.Fs}\n",
    "    }\n",
    "\n",
    "def freqCreator():\n",
    "    return {\n",
    "        iq.gradient: {},\n",
    "        iq.unwrapPhase: {},\n",
    "        iq.phase: {},\n",
    "    }\n",
    "\n",
    "def runForExperiment(df, target, mode, query, configurations):\n",
    "    if df[target].dtype == object:\n",
    "        df[target] = df[target].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else int(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[target] = label_encoder.fit_transform(df[target])\n",
    "\n",
    "    best_config = None\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_X_test = None\n",
    "    best_y_test = None\n",
    "\n",
    "    for config_name, config_methods in configurations.items():\n",
    "        try:\n",
    "            if mode == 'freq':\n",
    "                temp = iq.apply(methods={**freqCreator(), **config_methods}, frame=df['frame'])\n",
    "            else:\n",
    "                temp = iq.apply(methods=config_methods, frame=df['frame'])\n",
    "\n",
    "            if mode == 'IQSplit':\n",
    "                temp = temp.apply(lambda x: np.concatenate([np.real(x), np.imag(x)]))\n",
    "            else:\n",
    "                temp = temp.apply(lambda x: x[:min(2000, len(x))])\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(temp, df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "            y_train_encoded = to_categorical(y_train)\n",
    "            y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "            X_train = tf.convert_to_tensor(X_train.tolist(), dtype=tf.float32)\n",
    "            X_test = tf.convert_to_tensor(X_test.tolist(), dtype=tf.float32)\n",
    "\n",
    "            model, benign_accuracy = RV_CNN(X_train, y_train_encoded, X_test, y_test_encoded)\n",
    "            print(f\"Configuration: {config_name}, Mode: {mode}, Accuracy: {benign_accuracy}\")\n",
    "\n",
    "            if benign_accuracy > best_accuracy:\n",
    "                best_accuracy = benign_accuracy\n",
    "                best_config = config_name\n",
    "                best_model = model\n",
    "                best_X_test = X_test\n",
    "                best_y_test = y_test_encoded\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in configuration {config_name}: {e}\")\n",
    "\n",
    "    if best_model:\n",
    "        print(f\"Best configuration for {mode}: {best_config} with accuracy {best_accuracy}\")\n",
    "\n",
    "        attack_configurations = [\n",
    "            {'type': 'fgsm', 'params': {'epsilon': 0.01, 'targeted': False}},\n",
    "            {'type': 'pgd', 'params': {'epsilon': 0.01, 'alpha': 0.001, 'num_steps': 40, 'targeted': False}},\n",
    "            {'type': 'cw', 'params': {'confidence': 0.0, 'targeted': False, 'max_iterations': 1000, 'learning_rate': 0.01}},\n",
    "        ]\n",
    "\n",
    "        for attack in attack_configurations:\n",
    "            try:\n",
    "                if attack['type'] == 'fgsm':\n",
    "                    X_adv = fgsm_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "                elif attack['type'] == 'pgd':\n",
    "                    X_adv = pgd_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "                elif attack['type'] == 'cw':\n",
    "                    X_adv = cw_attack(best_model, best_X_test, best_y_test, **attack['params'])\n",
    "\n",
    "                y_pred_adv = np.argmax(best_model.predict(X_adv), axis=1)\n",
    "                y_true = np.argmax(best_y_test, axis=1)\n",
    "                metrics = evaluate_performance(y_true, y_pred_adv)\n",
    "\n",
    "                print(f\"Attack: {attack['type']}, Metrics: {metrics}\")\n",
    "                logging.info(f\"Attack: {attack['type']}, Metrics: {metrics}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during {attack['type']} attack: {e}\")\n",
    "\n",
    "# Queries\n",
    "queries = {\n",
    "    'E1': {'pkl_file': 'data/E1.pkl', 'target': 'dvc'},\n",
    "    'E2': {'pkl_file': 'data/E2.pkl', 'target': 'pos'},\n",
    "    'E3': {'pkl_file': 'data/E3.pkl', 'target': 'pos'},\n",
    "    'E4': {'pkl_file': 'data/E4.pkl', 'target': 'dvc'},\n",
    "    'E5': {'pkl_file': 'data/E5.pkl', 'target': 'pos'},\n",
    "    'E6': {'pkl_file': 'data/E6.pkl', 'target': 'dvc'},\n",
    "    'E7': {'pkl_file': 'data/E7.pkl', 'target': 'dvc'},\n",
    "    'E8': {'pkl_file': 'data/E8.pkl', 'target': 'dvc'},\n",
    "    'E9': {'pkl_file': 'data/E9.pkl', 'target': 'dvc'},\n",
    "    'E10': {'pkl_file': 'data/E10.pkl', 'target': 'dvc'},\n",
    "    'E11': {'pkl_file': 'data/E11.pkl', 'target': 'dvc'},\n",
    "}\n",
    "\n",
    "# Configurations\n",
    "configurations = {\n",
    "    'butter4MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=4e6),\n",
    "    'butter4MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=4e6),\n",
    "    'butter2MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=2e6),\n",
    "    'butter2MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=2e6),\n",
    "    'butter2MHz_Fs5MHz': configCreator(downSampleRate=20, cutoff=2e6),\n",
    "    'butter1MHz_Fs100MHz': configCreator(downSampleRate=1, cutoff=1e6),\n",
    "    'butter1MHz_Fs10MHz': configCreator(downSampleRate=10, cutoff=1e6),\n",
    "    'butter1MHz_Fs5MHz': configCreator(downSampleRate=20, cutoff=1e6),\n",
    "    'butter1MHz_Fs2.5MHz': configCreator(downSampleRate=40, cutoff=1e6),\n",
    "}\n",
    "\n",
    "# Experiments\n",
    "Experiments = ['freq', 'IQSplit', 'RV_CNN']\n",
    "\n",
    "for query_name, query_info in queries.items():\n",
    "    try:\n",
    "        with open(query_info['pkl_file'], 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "\n",
    "        df = process_dataframe(df)\n",
    "\n",
    "        for experiment in Experiments:\n",
    "            runForExperiment(df, query_info['target'], experiment, query_info, configurations)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query {query_name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
